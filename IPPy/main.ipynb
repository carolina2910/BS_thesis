{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from typing import Tuple, Dict, Optional, List\n",
        "\n",
        "from IPPy.utilities.data import TrainDataset\n",
        "from IPPy.utilities.test import *\n",
        "from IPPy.nn.models import UNet, ResUNet\n",
        "from IPPy.utilities._utilities import *\n",
        "from IPPy.utilities.metrics import *\n",
        "from IPPy.nn.train import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Data paths\n",
        "INPUT_PATH_TRAIN = 'data/input/Canova4'\n",
        "OUTPUT_PATH_TRAIN = 'data/input/Canova2'\n",
        "INPUT_PATH_TEST = 'data/target/Canova4_target_67932'\n",
        "OUTPUT_PATH_TEST = 'data/target/Canova2_target_67932'\n",
        "\n",
        "# Model parameters\n",
        "DATA_SHAPE = 512\n",
        "MIDDLE_CHANNELS = [64, 128, 256, 512, 1024]\n",
        "FINAL_ACTIVATION = 'sigmoid'\n",
        "\n",
        "# Training parameters\n",
        "N_EPOCHS = 100\n",
        "BATCH_SIZE = 6\n",
        "\n",
        "# Model and loss function options\n",
        "MODELS = ['UNet', 'ResUNet']\n",
        "LOSS_FUNCTIONS = ['MSE', 'L1']\n",
        "\n",
        "# Device configuration\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Output paths\n",
        "RESULTS_BASE_DIR = 'results'\n",
        "\n",
        "@staticmethod\n",
        "def get_output_dir(model_name, loss_name):\n",
        "    \"\"\"Generate output directory path for a specific model and loss.\"\"\"\n",
        "    return os.path.join(\n",
        "        RESULTS_BASE_DIR,\n",
        "        f'output_reconstruction_test_67932/{model_name}',\n",
        "        f'{N_EPOCHS}epochs_{BATCH_SIZE}batch_{loss_name}Loss'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    model_name: str,\n",
        "    loss_fn_name: str,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Train a model with specified configuration.\n",
        "    \n",
        "    Args:\n",
        "        model_name: Name of the model to train\n",
        "        loss_fn_name: Name of the loss function to use\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"TRAINING {model_name} WITH {loss_fn_name} LOSS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Setup paths\n",
        "    results_dir = get_output_dir(model_name, loss_fn_name)\n",
        "    create_directory(results_dir)\n",
        "    \n",
        "    weights_path = os.path.join(results_dir, 'model_weights.pth')\n",
        "    graphic_path = os.path.join(results_dir, 'loss_curve.png')\n",
        "    loss_file = os.path.join(results_dir, 'loss_values.csv')\n",
        "    \n",
        "    # Load dataset\n",
        "    print(f\"\\nLoading training data...\")\n",
        "    print(f\"  Input path: {INPUT_PATH_TRAIN}\")\n",
        "    print(f\"  Output path: {OUTPUT_PATH_TRAIN}\")\n",
        "    print(f\"  Files in input: {count_files(INPUT_PATH_TRAIN)}\")\n",
        "    print(f\"  Files in output: {count_files(INPUT_PATH_TRAIN)}\")\n",
        "    \n",
        "    train_data = TrainDataset(\n",
        "        in_path=INPUT_PATH_TRAIN,\n",
        "        out_path=INPUT_PATH_TRAIN,\n",
        "        data_shape=DATA_SHAPE\n",
        "    )\n",
        "    print(f\"  Dataset size: {len(train_data)}\")\n",
        "    \n",
        "    # Initialize model\n",
        "    print(f\"\\nInitializing {model_name} model...\")\n",
        "    model = get_model(model_name, MIDDLE_CHANNELS,FINAL_ACTIVATION )\n",
        "    \n",
        "    # Get loss function\n",
        "    loss_fn = get_loss_function(loss_fn_name)\n",
        "    print(f\"Loss function: {loss_fn_name}\")\n",
        "    \n",
        "    # Train\n",
        "    print(f\"\\nStarting training...\")\n",
        "    print(f\"  Epochs: {N_EPOCHS}\")\n",
        "    print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "    print(f\"  Device: {DEVICE}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    train(\n",
        "        model=model,\n",
        "        training_data=train_data,\n",
        "        loss_fn=loss_fn,\n",
        "        n_epochs=N_EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device=DEVICE,\n",
        "        graphic_path=graphic_path,\n",
        "        loss_file=loss_file\n",
        "    )\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {training_time/60:.2f} minutes\")\n",
        "    \n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), weights_path)\n",
        "    print(f\"Model weights saved to: {weights_path}\")\n",
        "    \n",
        "    clear_gpu_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing and visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(\n",
        "    model_name: str,\n",
        "    loss_fn_name: str, \n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Test a trained model and save results.\n",
        "    \n",
        "    Args:\n",
        "        model_name: Name of the model to test\n",
        "        loss_fn_name: Name of the loss function used during training\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary containing average metrics\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"TESTING {model_name} WITH {loss_fn_name} LOSS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Setup paths\n",
        "    results_dir = get_output_dir(model_name, loss_fn_name)\n",
        "    weights_path = os.path.join(results_dir, 'model_weights.pth')\n",
        "    output_dir = os.path.join(results_dir, 'single_images')\n",
        "    comparison_dir = os.path.join(results_dir, 'comparison')\n",
        "    metrics_file = os.path.join(results_dir, 'metrics.txt')\n",
        "    \n",
        "    create_directory(output_dir)\n",
        "    create_directory(comparison_dir)\n",
        "    \n",
        "    # Load model\n",
        "    print(f\"\\nLoading {model_name} model...\")\n",
        "    model = get_model(model_name).to(DEVICE)\n",
        "    \n",
        "    if os.path.exists(weights_path):\n",
        "        model.load_state_dict(torch.load(weights_path, map_location=DEVICE))\n",
        "        print(f\"Weights loaded from: {weights_path}\")\n",
        "    else:\n",
        "        print(f\"WARNING: Weights file not found at {weights_path}\")\n",
        "        print(\"Continuing with randomly initialized model.\")\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # Load test dataset\n",
        "    print(f\"\\nLoading test data...\")\n",
        "    print(f\"  Input path: {INPUT_PATH_TEST}\")\n",
        "    print(f\"  Output path: {OUTPUT_PATH_TEST}\")\n",
        "    \n",
        "    test_dataset = TrainDataset(\n",
        "        in_path=INPUT_PATH_TEST,\n",
        "        out_path=OUTPUT_PATH_TEST,\n",
        "        data_shape=DATA_SHAPE\n",
        "    )\n",
        "    print(f\"  Test dataset size: {len(test_dataset)}\")\n",
        "    \n",
        "    if len(test_dataset) == 0:\n",
        "        print(\"ERROR: No test images found!\")\n",
        "        return {}\n",
        "    \n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "    \n",
        "    # Initialize metrics accumulators\n",
        "    metrics_sum = {\n",
        "        're_input_target': 0, 'psnr_input_target': 0,\n",
        "        'ssim_input_target': 0, 'rmse_input_target': 0,\n",
        "        're_pred_target': 0, 'psnr_pred_target': 0,\n",
        "        'ssim_pred_target': 0, 'rmse_pred_target': 0\n",
        "    }\n",
        "    \n",
        "    # Process images\n",
        "    print(f\"\\nProcessing test images...\")\n",
        "    with torch.no_grad():\n",
        "        for idx, (x, y) in enumerate(test_loader):\n",
        "            # Get prediction\n",
        "            x_device = x.to(DEVICE)\n",
        "            x_pred = model(x_device).detach().cpu()\n",
        "            \n",
        "            # Calculate metrics\n",
        "            metrics = calculate_metrics(x, y, x_pred)\n",
        "            for key, value in metrics.items():\n",
        "                metrics_sum[key] += value\n",
        "            \n",
        "            # Save individual prediction\n",
        "            save_image(x_pred, os.path.join(output_dir, f'predicted_{idx}.png'))\n",
        "            \n",
        "            # Save comparison plot\n",
        "            save_comparison_plot(\n",
        "                x, y, x_pred,\n",
        "                os.path.join(comparison_dir, f'comparison_{idx}.png'),\n",
        "                idx\n",
        "            )\n",
        "            \n",
        "            if (idx + 1) % 10 == 0:\n",
        "                print(f\"  Processed {idx + 1}/{len(test_dataset)} images\")\n",
        "    \n",
        "    # Calculate averages\n",
        "    n_images = len(test_dataset)\n",
        "    metrics_avg = {key: value / n_images for key, value in metrics_sum.items()}\n",
        "    \n",
        "    # Save metrics to file\n",
        "    with open(metrics_file, 'w') as f:\n",
        "        f.write(f\"Testing Results for {model_name} with {loss_fn_name} Loss\\n\")\n",
        "        f.write(\"=\"*80 + \"\\n\\n\")\n",
        "        f.write(f\"Number of test images: {n_images}\\n\\n\")\n",
        "        f.write(\"Average Metrics:\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        f.write(\"\\nInput-Target Comparison:\\n\")\n",
        "        f.write(f\"  RE:   {metrics_avg['re_input_target']:.4f}\\n\")\n",
        "        f.write(f\"  PSNR: {metrics_avg['psnr_input_target']:.4f}\\n\")\n",
        "        f.write(f\"  SSIM: {metrics_avg['ssim_input_target']:.4f}\\n\")\n",
        "        f.write(f\"  RMSE: {metrics_avg['rmse_input_target']:.4f}\\n\")\n",
        "        f.write(\"\\nPrediction-Target Comparison:\\n\")\n",
        "        f.write(f\"  RE:   {metrics_avg['re_pred_target']:.4f}\\n\")\n",
        "        f.write(f\"  PSNR: {metrics_avg['psnr_pred_target']:.4f}\\n\")\n",
        "        f.write(f\"  SSIM: {metrics_avg['ssim_pred_target']:.4f}\\n\")\n",
        "        f.write(f\"  RMSE: {metrics_avg['rmse_pred_target']:.4f}\\n\")\n",
        "    \n",
        "    print(f\"\\nMetrics saved to: {metrics_file}\")\n",
        "    print(\"\\nAverage Metrics:\")\n",
        "    print(f\"  Prediction PSNR: {metrics_avg['psnr_pred_target']:.4f}\")\n",
        "    print(f\"  Prediction SSIM: {metrics_avg['ssim_pred_target']:.4f}\")\n",
        "    \n",
        "    return metrics_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"NEURAL NETWORK TRAINING AND TESTING PIPELINE\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    \n",
        "    # Display configuration\n",
        "    print(\"\\nConfiguration:\")\n",
        "    print(f\"  Data shape: {DATA_SHAPE}\")\n",
        "    print(f\"  Epochs: {N_EPOCHS}\")\n",
        "    print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "    print(f\"  Device: {DEVICE}\")\n",
        "    print(f\"  Models: {', '.join(MODELS)}\")\n",
        "    print(f\"  Loss functions: {', '.join(LOSS_FUNCTIONS)}\")\n",
        "    \n",
        "    # Train all models\n",
        "    for model_name in MODELS:\n",
        "        for loss_fn_name in LOSS_FUNCTIONS:\n",
        "            train_model(model_name, loss_fn_name)\n",
        "    \n",
        "    # Test all models\n",
        "    for model_name in MODELS:\n",
        "        for loss_fn_name in LOSS_FUNCTIONS:\n",
        "            test_model(model_name, loss_fn_name)\n",
        "    \n",
        "    # Create visualizations\n",
        "    plot_loss_comparison(LOSS_FUNCTIONS, MODELS, get_output_dir)\n",
        "    create_metrics_comparison_table(LOSS_FUNCTIONS, MODELS, get_output_dir)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
